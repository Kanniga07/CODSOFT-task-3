This project is an image captioning system that creates informative captions for photographs by fusing natural language processing with computer vision. It makes use of a Vision-Encoder-Decoder model (ViT-GPT2), which combines GPT-2 for text caption generation with a Vision Transformer (ViT) for picture feature extraction. Furthermore, a pre-trained ResNet50 model is employed for feature extraction, demonstrating an alternate approach to picture analysis.After processing an input image, the system uses the Vision Transformer to extract its features and GPT-2 to create a caption. For improved visualization, it also comes with a tool to show the image along with the generated caption. This research shows how state-of-the-art deep learning models can be integrated to produce intelligent, automated image captioning.
